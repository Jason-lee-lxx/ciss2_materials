{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intro: DeepPavlov sequence-to-sequence tutorial\n",
    "\n",
    "In this tutorial we are going to implement [sequence-to-sequence](https://arxiv.org/abs/1409.3215) model in DeepPavlov.\n",
    "\n",
    "Sequence-to-sequence is the concept of mapping input sequence to target sequence. Sequence-to-sequence models consist of two main components: encoder and decoder. Encoder is used to encode the input sequence to dense representation and decoder uses this dense representation to generate target sequence.\n",
    "\n",
    "![sequence-to-sequence](https://cdn-images-1.medium.com/max/1400/1*Ismhi-muID5ooWf3ZIQFFg.png)\n",
    "\n",
    "(image credit: [towardsdatascience.com](https://towardsdatascience.com))\n",
    "\n",
    "To implement this model in DeepPavlov we have to code some DeepPavlov abstractions:\n",
    "* **DatasetReader** to read the data\n",
    "* **DatasetIterator** to generate batches\n",
    "* **Vocabulary** to convert words to indexes\n",
    "* **Model** to train it and then use it\n",
    "* and some other components for pre- and postprocessing\n",
    "\n",
    "### Probably the most usefull blog post about tensorflow I've seen\n",
    "or why `tf.shape != tensor.get_shape`\n",
    "\n",
    "[TensorFlow: Shapes and dynamic dimensions](https://blog.metaflow.fr/shapes-and-dynamic-dimensions-in-tensorflow-7b1fe79be363)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Designations\n",
    "    \n",
    "for clarity we add the following suffixes to the end of python variables:\n",
    "\n",
    "`_ph` - tf.placeholder\n",
    "`_layer` - tf.keras.layer\n",
    "`_op` - tensorflow operation (remember that tf.Tensor is not a set of valuet, it is a node in computational graph)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pdb\n",
    "import json\n",
    "from itertools import chain\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import deeppavlov\n",
    "from deeppavlov import build_model\n",
    "from deeppavlov.core.data.dataset_reader import DatasetReader\n",
    "from deeppavlov.core.common.registry import register"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.13.1', '0.3.1')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__, deeppavlov.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "MAXLEN = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download & extract dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has already been downloaded\n"
     ]
    }
   ],
   "source": [
    "from deeppavlov.core.data.utils import download_decompress\n",
    "\n",
    "dataset_path = './personachat'\n",
    "\n",
    "if not os.path.exists(dataset_path):\n",
    "    download_decompress('http://files.deeppavlov.ai/datasets/personachat_v2.tar.gz', dataset_path)\n",
    "else:\n",
    "    print('Dataset has already been downloaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DatasetReader\n",
    "\n",
    "DatasetReader is used to read and parse data from files. Here, we define new PersonaChatDatasetReader which reads [PersonaChat dataset](https://arxiv.org/abs/1801.07243).\n",
    "\n",
    "PersonaChat dataset consists of dialogs and user personalities.\n",
    "\n",
    "User personality is described by four sentences, e.g.:\n",
    "\n",
    "    i like to remodel homes.\n",
    "    i like to go hunting.\n",
    "    i like to shoot a bow.\n",
    "    my favorite holiday is halloween.\n",
    "    \n",
    "But we will be using only dialogues in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@register('personachat_dataset_reader')  # to use component later in train config it sould be registered\n",
    "class PersonaChatDatasetReader(DatasetReader):\n",
    "    \"\"\"\n",
    "    PersonaChat dataset from\n",
    "    Zhang S. et al. Personalizing Dialogue Agents: I have a dog, do you have pets too?\n",
    "    https://arxiv.org/abs/1801.07243\n",
    "    Also, this dataset is used in ConvAI2 http://convai.io/\n",
    "    This class reads dataset to the following format:\n",
    "    [{\n",
    "        'persona': [list of persona sentences],\n",
    "        'x': input utterance,\n",
    "        'y': output utterance,\n",
    "        'dialog_history': list of previous utterances\n",
    "        'candidates': [list of candidate utterances]\n",
    "        'y_idx': index of y utt in candidates list\n",
    "      },\n",
    "       ...\n",
    "    ]\n",
    "    \"\"\"\n",
    "    def read(self, dir_path: str, mode='self_original', verbose=False):\n",
    "        if verbose:\n",
    "            print('Reading dataset...')\n",
    "        dir_path = Path(dir_path)\n",
    "        dataset = {}\n",
    "        for dt in ['train', 'valid', 'test']:\n",
    "            dataset[dt] = self._parse_data(dir_path / f'{dt}_{mode}.txt', verbose)\n",
    "\n",
    "        print('Done\\n')\n",
    "        return dataset\n",
    "\n",
    "    @staticmethod\n",
    "    def _parse_data(filename, verbose):\n",
    "        examples = []\n",
    "        if verbose:\n",
    "            print(filename)\n",
    "        curr_persona = []\n",
    "        curr_dialog_history = []\n",
    "        persona_done = False\n",
    "        with filename.open('r') as fin:\n",
    "            for line in fin:\n",
    "                line = ' '.join(line.strip().split(' ')[1:])\n",
    "                your_persona_pref = 'your persona: '\n",
    "                if line[:len(your_persona_pref)] == your_persona_pref and persona_done:\n",
    "                    curr_persona = [line[len(your_persona_pref):]]\n",
    "                    curr_dialog_history = []\n",
    "                    persona_done = False\n",
    "                elif line[:len(your_persona_pref)] == your_persona_pref:\n",
    "                    curr_persona.append(line[len(your_persona_pref):])\n",
    "                else:\n",
    "                    persona_done = True\n",
    "                    x, y, _, candidates = line.split('\\t')\n",
    "                    candidates = candidates.split('|')\n",
    "                    example = {\n",
    "                        'persona': curr_persona,\n",
    "                        'x': x,\n",
    "                        'y': y,\n",
    "                        'dialog_history': curr_dialog_history[:],\n",
    "                        'candidates': candidates,\n",
    "                        'y_idx': candidates.index(y)\n",
    "                    }\n",
    "                    curr_dialog_history.extend([x, y])\n",
    "                    examples.append(example)\n",
    "\n",
    "        return examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read dataset, check size and sample some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset...\n",
      "personachat/train_self_original.txt\n",
      "personachat/valid_self_original.txt\n",
      "personachat/test_self_original.txt\n",
      "Done\n",
      "\n",
      "train \t: 65719\n",
      "valid \t: 7801\n",
      "test \t: 7512\n"
     ]
    }
   ],
   "source": [
    "data = PersonaChatDatasetReader().read('./personachat', verbose=True)\n",
    "\n",
    "for k in data:\n",
    "    print(k, '\\t:', len(data[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'persona': ['i go to at least 10 concerts a year.',\n",
       "  'i work in retail.',\n",
       "  'madonna is my all time favorite.',\n",
       "  'lady gaga is my current favorite singer.'],\n",
       " 'x': 'they are both greyhounds . their names are tom and jerry .',\n",
       " 'y': 'that is cute ! how old are they ?',\n",
       " 'dialog_history': ['hey , what are you up to ?',\n",
       "  'hello , i am listening to lady gaga , do you like her ?',\n",
       "  'i prefer rock music , like led zeppelin .',\n",
       "  'madonna is my first favorite . do you go to a lot of concerts ?',\n",
       "  'i would if i could , but i have a farm to maintain .',\n",
       "  'i work at the mall , so i am close to the venue .',\n",
       "  'i prefer hiking outdoors and photography rather than crowded malls .',\n",
       "  'pays well , lol . i make great money as the manager .',\n",
       "  'work is tiring . i would love to travel the world instead .',\n",
       "  'i would love to travel as well .',\n",
       "  'staying here is fine too though . my two dogs keep me company .',\n",
       "  'i love dogs ! what kind do you have ?'],\n",
       " 'candidates': ['my girlfriend eloped w my best friend',\n",
       "  'we should get a cleaner to clean out all the tofu my wife keeps cooking . gross !',\n",
       "  'you sound young and fabulous . thanks for chatting !',\n",
       "  'how do you like new york ?',\n",
       "  'my sweet puppy will have the rings',\n",
       "  'green ones ! ha ha . only because that is my favorite .',\n",
       "  'i like to play soccer , i love games of throne and a vegan',\n",
       "  'ah that is nice . like my turtles . you have pets ?',\n",
       "  'peanut butter on my pizza',\n",
       "  'which show were you in ?',\n",
       "  'i still stay with my parents',\n",
       "  'jokes sometimes goes serious and it is not good',\n",
       "  'i play for midlands high school . our mascot is the cougars',\n",
       "  'that sounds terrible ! but would probably make you rich .',\n",
       "  'oh i like to all the time but everyone wants me everywhere',\n",
       "  'i am super afraid of heights',\n",
       "  'yeah , me and my grandma go there all the time .',\n",
       "  'i like to attend social gatherings .',\n",
       "  'i do not blame you . although i have to watch out for shellfish , i am allergic .',\n",
       "  'that is cute ! how old are they ?'],\n",
       " 'y_idx': 19}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train'][100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset iterator\n",
    "\n",
    "Dataset iterator is used to generate batches from parsed dataset (DatasetReader). Let's extract only `x` and `y` from parsed dataset and use them to predict sentence `y` by sentence `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeppavlov.core.data.data_learning_iterator import DataLearningIterator\n",
    "\n",
    "@register('personachat_iterator')\n",
    "class PersonaChatIterator(DataLearningIterator):\n",
    "    def split(self, *args, **kwargs):\n",
    "        for dt in ['train', 'valid', 'test']:\n",
    "            setattr(self, dt, self._to_tuple(getattr(self, dt)))\n",
    "\n",
    "    @staticmethod\n",
    "    def _to_tuple(data):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            list of (x, y)\n",
    "        \"\"\"\n",
    "        return list(map(lambda x: (x['x'], x['y']), data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: i am so sorry . my mother died during child birth and my father died 3 years ago .\n",
      "y: sorry to hear that . it must have been so hard\n",
      "----------\n",
      "x: its mine , my dads and brothers cat i live with them\n",
      "y: cooking is what i love\n",
      "----------\n",
      "x: oh . i like lasagna so much\n",
      "y: we sell lasagna at the aldis store i work part time at\n",
      "----------\n",
      "x: great here . my name is reginald . you ?\n",
      "y: good to hear ! nice to meet you my name is brianna .\n",
      "----------\n",
      "x: i am usually there to run marathons\n",
      "y: wow that is awesome . i am 300 pounds so i have not run a marathon before .\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "iterator = PersonaChatIterator(data)\n",
    "batch_generator = iterator.gen_batches(5, 'train')\n",
    "batch = next(batch_generator)\n",
    "for x, y in zip(*batch):\n",
    "    print('x:', x)\n",
    "    print('y:', y)\n",
    "    print('----------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer\n",
    "Splits utterance into tokens (words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/not_a_robot/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/not_a_robot/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package perluniprops to\n",
      "[nltk_data]     /home/not_a_robot/nltk_data...\n",
      "[nltk_data]   Package perluniprops is already up-to-date!\n",
      "[nltk_data] Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]     /home/not_a_robot/nltk_data...\n",
      "[nltk_data]   Package nonbreaking_prefixes is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['I', \"'d\", 'like', 'to', 'tokenize', 'some', 'text']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from deeppavlov.models.tokenizers.lazy_tokenizer import LazyTokenizer\n",
    "tokenizer = LazyTokenizer()\n",
    "tokenizer([\"I'd like to tokenize some text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary\n",
    "\n",
    "Vocabulary object prepares mapping from tokens to token indices.\n",
    "It uses train data to build this mapping.\n",
    "\n",
    "We will implement DialogVocab (inherited from SimpleVocabulary) wich adds all tokens from `x` and `y` utterances to vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeppavlov.core.data.simple_vocab import SimpleVocabulary\n",
    "\n",
    "@register('dialog_vocab')\n",
    "class DialogVocab(SimpleVocabulary):\n",
    "    def fit(self, *args):\n",
    "        tokens = chain(*args)\n",
    "        super().fit(tokens)\n",
    "\n",
    "    def __call__(self, batch, **kwargs):\n",
    "        indices_batch = []\n",
    "        for utt in batch:\n",
    "            tokens = [self[token] for token in utt]\n",
    "            indices_batch.append(tokens)\n",
    "        return indices_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create instance of DialogVocab. We define save and load paths, minimal frequence of tokens which are added to vocabulary and set of special tokens.\n",
    "\n",
    "Special tokens are:\n",
    "* <PAD\\> - padding\n",
    "* <SOS\\> - start of sequence\n",
    "* <EOS\\> - end of sequence\n",
    "* <UNK\\> - unknown token - token which is not presented in vocabulary\n",
    "\n",
    "And fit it on tokens from *x* and *y*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-26 00:49:25.331 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 103: [loading vocabulary from /home/not_a_robot/Documents/random_notebooks/CISS/vocab.dict]\n",
      "2019-06-26 00:49:39.320 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 89: [saving vocabulary to /home/not_a_robot/Documents/random_notebooks/CISS/vocab.dict]\n"
     ]
    }
   ],
   "source": [
    "vocab = DialogVocab(\n",
    "    save_path='./vocab.dict',\n",
    "    load_path='./vocab.dict',\n",
    "    min_freq=2,\n",
    "    special_tokens=('<PAD>','<SOS>', '<EOS>', '<UNK>',),\n",
    "    unk_token='<UNK>'\n",
    ")\n",
    "\n",
    "vocab.fit(tokenizer(iterator.get_instances(data_type='train')[0]), tokenizer(iterator.get_instances(data_type='train')[1]))\n",
    "vocab.save()\n",
    "\n",
    "PAD_idx = vocab._t2i['<PAD>']\n",
    "SOS_idx = vocab._t2i['<SOS>']\n",
    "assert PAD_idx == 0, 'this is required by tf.keras'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11595"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of words in vocab\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i', 103487),\n",
       " ('.', 101599),\n",
       " ('you', 48296),\n",
       " ('?', 43771),\n",
       " (',', 39500),\n",
       " ('a', 34214),\n",
       " ('to', 32105),\n",
       " ('do', 30574),\n",
       " ('is', 28579),\n",
       " ('my', 26953)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.freqs.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can use vocabulary to encode tokenized text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 110, 12, 3, 3, 3, 6060, 2, 0, 0]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab([['<SOS>', 'this', 'is', 'tokenized', 'there_is_no_such_word_in_dataset', 'and_this', 'sentence', '<EOS>', '<PAD>', '<PAD>']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding\n",
    "\n",
    "To feed sequences of token indexes to neural model we should make their lengths equal. If sequence is too short we add <PAD\\> symbols to the end of sequence. If sequence is too long we just cut it.\n",
    "\n",
    "SentencePadder implements such behavior, it also adds <SOS\\> and <EOS\\> tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeppavlov.core.models.component import Component\n",
    "\n",
    "@register('sentence_padder')\n",
    "class SentencePadder(Component):\n",
    "    def __init__(self, length_limit, pad_token_id=0, start_token_id=1, end_token_id=2, *args, **kwargs):\n",
    "        self.length_limit = length_limit\n",
    "        self.pad_token_id = pad_token_id\n",
    "        self.start_token_id = start_token_id\n",
    "        self.end_token_id = end_token_id\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        for i in range(len(batch)):\n",
    "            batch[i] = batch[i][:self.length_limit]\n",
    "            batch[i] = [self.start_token_id] + batch[i] + [self.end_token_id]\n",
    "            batch[i] += [self.pad_token_id] * (self.length_limit + 2 - len(batch[i]))\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 110, 12, 75, 75, 149, 6060, 2], [1, 110, 76, 12, 456, 2, 0, 0]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padder = SentencePadder(length_limit=6)\n",
    "padded = padder(vocab(tokenizer(['this is very very long sentence that does not fit',\n",
    "                                 'this one is short'])))\n",
    "padded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reverse mapping, just apply vocab again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['<SOS>', 'this', 'is', 'very', 'very', 'long', 'sentence', '<EOS>'],\n",
       " ['<SOS>', 'this', 'one', 'is', 'short', '<EOS>', '<PAD>', '<PAD>']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab(padded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2seq model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/seq2seq_training.png)\n",
    "\n",
    "(image credit: Stanford cs224n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_seq2seq_graph(input_ph, target_ph, build_encoder_fn, build_decoder_fn, hidden_size, vocab_size, emb_size, dropout_rate, is_training_ph):\n",
    "    \"\"\"\n",
    "    Args\n",
    "        x_ph: input tokens placeholder\n",
    "        y_ph: expected output tokens placeholder (used at training time for input feeding)\n",
    "        build_encoder: function to build encoder graph\n",
    "        build_decoder: function to build decoder graph\n",
    "        hidden_dim: size of encoder rnn\n",
    "        vocab_size: number of words in the vocabulary\n",
    "        emb_dim: embedding size\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor [batch_size, maxlen, decoder_output_dim]\n",
    "    \"\"\"\n",
    "    # embedding is shared between encoder and decoder\n",
    "    embedding_layer = tf.keras.layers.Embedding(vocab_size, emb_size)\n",
    "    dropout_layer = tf.keras.layers.Dropout(rate=dropout_rate)\n",
    "    mask = tf.cast(input_ph, tf.bool)\n",
    "\n",
    "    encoder_outputs_op, encoder_state_op = build_encoder_fn(\n",
    "        input_ph,\n",
    "        embedding_layer,\n",
    "        dropout_layer,\n",
    "        hidden_size,\n",
    "        is_training_ph\n",
    "    )\n",
    "    decoder_op = build_decoder_fn(\n",
    "        encoder_outputs_op,\n",
    "        encoder_state_op,\n",
    "        target_ph,\n",
    "        embedding_layer,\n",
    "        dropout_layer,\n",
    "        is_training_ph,\n",
    "        mask\n",
    "    )\n",
    "    logits_layer = tf.keras.layers.Dense(vocab_size)\n",
    "    logits_op = logits_layer(decoder_op)\n",
    "    return logits_op\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_encoder(x_ph, embedding_layer, dropout_layer, hidden_dim, is_training_ph):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x_ph: input tokens placeholder\n",
    "        embedding_layer: tf.keras.Embedding object\n",
    "        dropout_layer: tf.keras.Dropout object\n",
    "        hidden_dim: size of rnn (also output size)\n",
    "        is_training_ph: is training mode flag\n",
    "\n",
    "    Returns:\n",
    "        encoder_outputs_op: tf.Tensor, [batch_size, maxlen, encoder_hidden_size]\n",
    "        encoder_state_op: tf.Tensor, [batch_size, encoder_hidden_size]\n",
    "    \"\"\"\n",
    "    # embed x, apply dropout if is_training\n",
    "    x_op = embedding_layer(x_ph)\n",
    "    x_op = dropout_layer(x_op, training=is_training_ph)\n",
    "\n",
    "    # make rnn layer and apply it to x\n",
    "    # rnn layer should return both encoded sequences and state\n",
    "    rnn_layer = tf.keras.layers.GRU(hidden_dim, return_sequences=True, return_state=True)\n",
    "    encoder_outputs_op, encoder_state_op = rnn_layer(x_op)\n",
    "\n",
    "    return encoder_outputs_op, encoder_state_op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test encoder.\n",
    "\n",
    "shapes should be `[batch_size, maxlen, encoder_hidden_size]` and `[batch_size, encoder_hidden_size]`\n",
    "\n",
    "i.e `[3, 11, 17]` and `[3, 17]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/not_a_robot/.local/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/not_a_robot/.local/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Test 1 passed\n",
      "Test 2 passed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'gru/transpose_1:0' shape=(?, 11, 7) dtype=float32>,\n",
       " <tf.Tensor 'gru/while/Exit_3:0' shape=(?, 7) dtype=float32>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "toy_batch_size = 3\n",
    "toy_vocab_size = 13\n",
    "toy_hidden_dim = 7\n",
    "toy_emb_size = 5\n",
    "toy_maxlen = 11\n",
    "\n",
    "toy_emb = tf.keras.layers.Embedding(toy_vocab_size, toy_emb_size, input_length=toy_maxlen)\n",
    "toy_dropout = tf.keras.layers.Dropout(rate=0.5)\n",
    "\n",
    "# toy_input = tf.cast(tf.random_uniform(shape=[toy_batch_size, toy_maxlen]) * toy_vocab_size, tf.int32)\n",
    "toy_input = tf.placeholder(tf.int64, [None, toy_maxlen])\n",
    "\n",
    "encoder_outputs_op, encoder_state_op = build_encoder(\n",
    "    toy_input, toy_emb, toy_dropout, toy_hidden_dim, True)\n",
    "\n",
    "if (encoder_outputs_op.shape[1:] == (toy_maxlen, toy_hidden_dim)):\n",
    "    print('Test 1 passed')\n",
    "else:\n",
    "    print('Problem with the shape')\n",
    "    print(f'Shape should be {(None, toy_maxlen, toy_hidden_dim)}')\n",
    "    print(f'But got {encoder_outputs_op.shape} instead')\n",
    "\n",
    "if (encoder_state_op.shape[1:] == (toy_hidden_dim)):\n",
    "    print('Test 2 passed')\n",
    "else:\n",
    "    print('Problem with the shape')\n",
    "    print(f'Shape should be {(None, toy_hidden_dim)}')\n",
    "    print(f'But got {encoder_state_op.shape} instead')\n",
    "\n",
    "encoder_outputs_op, encoder_state_op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla seq2seq decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_decoder(\n",
    "        encoder_otputs_op,\n",
    "        encoder_state_op,\n",
    "        target_ph,\n",
    "        embedding_layer,\n",
    "        dropout_layer,\n",
    "        is_training_ph,\n",
    "        encoder_mask_ph=None):\n",
    "    \"\"\"Decoder without attention\n",
    "    it ignores encoder_otputs_op and uses only encoder_state_op to generate sequence\n",
    "\n",
    "    Args:\n",
    "        encoder_otputs_op: used only to get max_len\n",
    "        encoder_state_op: state of the encoder RNN, [batch_size, hidden_dim]\n",
    "        enc_mask_ph: ignored\n",
    "        target_ph: target placeholder, used at training time for input feeding\n",
    "        embedding_layer: tf.keras.Embedding object\n",
    "        dropout_layer: tf.keras.Dropout object\n",
    "        is_training_ph: is training mode flag\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor [batch_size, max_len, hidden_dim]\n",
    "    \"\"\"\n",
    "    _, max_len, hidden_dim = encoder_otputs_op.get_shape()\n",
    "    _, max_len, hidden_dim = _, max_len.value, hidden_dim.value\n",
    "\n",
    "    batch_size_op = tf.shape(encoder_otputs_op)[0]\n",
    "    vocab_size = embedding_layer.input_dim\n",
    "\n",
    "    # make decoder cell layer\n",
    "    decoder_cell = tf.keras.layers.GRUCell(hidden_dim)\n",
    "    # make decoder output projection layer (projects to vocabulary space)\n",
    "    decoder_output_proj_layer = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    # first decoder input is start-of-sentence token\n",
    "    decoder_input_op = tf.ones([batch_size_op]) * SOS_idx\n",
    "    # first decoder state is last encoder state\n",
    "    decoder_state_op = encoder_state_op\n",
    "    # in this list we will store the logits of predicted sequence\n",
    "    output_logits = []\n",
    "\n",
    "    for i in range(max_len):\n",
    "        decoder_input_emb_op = embedding_layer(decoder_input_op)\n",
    "\n",
    "        # for some complicated reasons, we must to expand_dims on state\n",
    "        # decoder_cell returns output and states, in the case of GRU, states and output are the same\n",
    "        decoder_state_op, _ = decoder_cell(decoder_input_emb_op, tf.expand_dims(decoder_state_op, 1))\n",
    "\n",
    "        decoder_output_logit_op = decoder_output_proj_layer(decoder_state_op)\n",
    "        output_logits.append(decoder_output_logit_op)\n",
    "\n",
    "        # if training, use input feeding i.e. teacher forcing\n",
    "        decoder_input_op = tf.cond(is_training_ph,\n",
    "                                   lambda: target_ph[:, i],\n",
    "                                   lambda: tf.argmax(decoder_output_logit_op, axis=1))\n",
    "\n",
    "    output_logits_op = tf.stack(output_logits, axis=1)\n",
    "    return output_logits_op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'stack:0' shape=(?, 11, 13) dtype=float32>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "toy_batch_size = 3\n",
    "toy_vocab_size = 13\n",
    "toy_hidden_dim = 7\n",
    "toy_emb_size = 5\n",
    "toy_maxlen = 11\n",
    "\n",
    "toy_emb = tf.keras.layers.Embedding(toy_vocab_size, toy_emb_size, input_length=toy_maxlen)\n",
    "toy_dropout = tf.keras.layers.Dropout(rate=0.5)\n",
    "\n",
    "toy_input = tf.placeholder(tf.int64, [None, toy_maxlen])\n",
    "toy_target = tf.placeholder(tf.int64, [None, toy_maxlen])\n",
    "toy_mask = tf.placeholder(tf.bool, [None, toy_maxlen])\n",
    "\n",
    "is_training_ph = tf.placeholder_with_default(tf.constant(True), shape=())\n",
    "\n",
    "encoder_outputs_op, encoder_state_op = build_encoder(\n",
    "    toy_input, toy_emb, toy_dropout, toy_hidden_dim, is_training_ph)\n",
    "\n",
    "toy_logits_op = build_decoder(\n",
    "    encoder_outputs_op, encoder_state_op, toy_target, toy_emb, toy_dropout, is_training_ph, toy_mask\n",
    ")\n",
    "\n",
    "if (toy_logits_op.shape[1:] == (toy_maxlen, toy_vocab_size)):\n",
    "    print('Test passed')\n",
    "else:\n",
    "    print('Problem with the shape')\n",
    "    print(f'Shape should be {(None, toy_maxlen, toy_vocab_size)}')\n",
    "    print(f'But got {toy_logits_op.shape} instead')\n",
    "\n",
    "toy_logits_op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_logits_op = build_seq2seq_graph(\n",
    "    toy_input, toy_target, build_encoder, build_decoder, toy_hidden_dim, toy_vocab_size, toy_emb_size, 0.5, is_training_ph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder with attention math\n",
    "\n",
    "Decoder is much more tricky then encoder, especially with attention.\n",
    "So it would be better for us to write down all decoder operations mathematically.\n",
    "\n",
    "Let $m$ be the length of a source sequence, $h$ be dimension of encoder output, $\\operatorname E \\in \\mathbb{R}^{ vocab\\_size \\times emb\\_size}$ - embedding matrix.\n",
    "\n",
    "Before encoding we have:\n",
    "$$\n",
    "\\mathbf{h}_i^{enc} \\in \\mathbb{R}^h - \\text{encoder output at i-th timestamp}\\\\\n",
    "\\mathbf{h}_m^{enc} - \\text{last encoder output (encoder state)}\\\\\n",
    "$$\n",
    "\n",
    "#### Zeroth step\n",
    "\n",
    "At the zeroth decoding step we sould construct decoder **input** and decoder **initial state**.\n",
    "Decoder **initial state** is encoder state.\n",
    "Decoder **input** is attention vector with SOS-token embedding as **query**.\n",
    "\n",
    "Let $sos$ be SOS-token index in embedding matrix.\n",
    "\n",
    "$$\n",
    "\\mathbf{h}_o^{dec} = \\mathbf{h}_m\\\\\n",
    "\\mathbf{e}_0 = \\operatorname{E}[sos]\\\\\n",
    "% \\mathbf{o}_0 = \\mathbf 0, \\mathbf{o}_0 \\in \\mathbb{R}^h\\\\\n",
    "% \\mathbf{h}_1^{dec} = \\operatorname{Decoder}([e_0; o_0])\n",
    "$$\n",
    "\n",
    "#### t-th step, t > 0\n",
    "\n",
    "At t-th step decoder **input** is attention vector with previous predicted token embedding as **query**.\n",
    "\n",
    "**Note:** at training time we use **teacher forcing** (it is also called input feeding) that means that instead of using previous predicted token decoder uses previous true token from target sequence.\n",
    "\n",
    "\n",
    "#### Attention\n",
    "\n",
    "When we got decoder state $h_1$, we can compute attention vector.\n",
    "\n",
    "Let $\\operatorname{W}_{attProj} \\in \\mathbb{R}^{h \\times h}$ be attention weighs, $\\mathbf{s}$ be attention scores, $\\mathbf{e}_t$ - embedding of the previous predicted token.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbf{s}_{t, i} &= (\\mathbf{e}_t)^T \\operatorname{W}_{attProj} \\mathbf{h}_i^{enc}\\\\\n",
    "\\mathbf{\\alpha}_t &= \\operatorname{Softmax}(\\mathbf{s}_t) \\text{  }\\\\\n",
    "\\mathbf{a}_t &= \\sum_i^m \\alpha_{t, i} \\mathbf{h}_i^{enc}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Or in terms of **query keys ans values**:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbf{s}_{t, i} &= (\\mathbf{q}_t)^T \\operatorname{W}_{attProj} \\mathbf{k}\\\\\n",
    "\\mathbf{\\alpha}_t &= \\operatorname{Softmax}(\\mathbf{s}_t) \\text{  }\\\\\n",
    "\\mathbf{a}_t &= \\sum_i^m \\alpha_{t, i} \\mathbf{v}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_masked(values, mask):\n",
    "    masked_values = -np.inf * (1 - tf.cast(mask, tf.float32)) + values\n",
    "    return tf.nn.softmax(masked_values, 2)\n",
    "\n",
    "def build_decoder_with_attention(\n",
    "        encoder_outputs_op,\n",
    "        encoder_state_op,\n",
    "        target_ph,\n",
    "        embedding_layer,\n",
    "        dropout_layer,\n",
    "        is_training_ph,\n",
    "        encoder_mask_ph):\n",
    "    \"\"\"Decoder with Luong attention\n",
    "    https://arxiv.org/abs/1508.04025\n",
    "\n",
    "    Args:\n",
    "        encoder_otputs_op: used only to get max_len\n",
    "        encoder_state_op: state of the encoder RNN, [batch_size, hidden_dim]\n",
    "        enc_mask_ph: ignored\n",
    "        target_ph: target placeholder, used at training time for input feeding\n",
    "        embedding_layer: tf.keras.Embedding object\n",
    "        dropout_layer: tf.keras.Dropout object\n",
    "        is_training_ph: is training mode flag\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor [batch_size, max_len, hidden_dim]\n",
    "    \"\"\"    \n",
    "    _, max_len, hidden_dim = encoder_outputs_op.get_shape()\n",
    "    _, max_len, hidden_dim = _, max_len.value, hidden_dim.value\n",
    "\n",
    "    batch_size_op = tf.shape(encoder_outputs_op)[0]\n",
    "    vocab_size = embedding_layer.input_dim\n",
    "\n",
    "    # make decoder cell layer\n",
    "    decoder_cell = tf.keras.layers.GRUCell(hidden_dim)\n",
    "    # make decoder output projection layer (projects to vocabulary space)\n",
    "    decoder_output_proj_layer = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    # first decoder input is start-of-sentence token\n",
    "    decoder_input_op = tf.ones([batch_size_op], dtype=tf.int64) * SOS_idx\n",
    "    # first decoder state is last encoder state\n",
    "    decoder_state_op = encoder_state_op\n",
    "    # in this list we will store the logits of predicted sequence\n",
    "    output_logits = []\n",
    "\n",
    "    # attention-related variables:\n",
    "    attention_proj_layer = tf.keras.layers.Dense(hidden_dim, use_bias=False)\n",
    "    attention_keys_op = attention_proj_layer(encoder_outputs_op)  # W_attProj @ h_enc\n",
    "    attention_values_op = encoder_outputs_op\n",
    "    attention_query_op = decoder_state_op\n",
    "\n",
    "    for i in range(max_len):\n",
    "        # compute input tensor for decoder rnn\n",
    "        decoder_input_emb_op = embedding_layer(decoder_input_op)\n",
    "\n",
    "        # apply attention with decoder_input_emb_op as query\n",
    "        attention_query_op = tf.expand_dims(decoder_state_op, 1)  # [batch_size, 1, hidden]\n",
    "        attention_scores_op = tf.matmul(attention_query_op, attention_keys_op, transpose_b=True)  # [batch_size, 1, maxlen]\n",
    "\n",
    "        attention_probs_op = softmax_masked(attention_scores_op, tf.expand_dims(encoder_mask_ph, 1))\n",
    "        attention_probs_op = tf.nn.softmax(attention_scores_op, 2)  # [batch_size, 1, maxlen]\n",
    "        attention_vec_op = tf.matmul(attention_probs_op, attention_values_op)  # [batch_size, 1, hidden]\n",
    "        attention_vec_op = tf.squeeze(attention_vec_op, 1)  # [batch_size, hidden]\n",
    "\n",
    "        # for some complicated reasons, we must to expand_dims(decoder_state_op, 1) on state\n",
    "        # decoder_cell returns output and states, in the case of GRU, states and output are the same\n",
    "        decoder_state_op, _ = decoder_cell(attention_vec_op, tf.expand_dims(decoder_state_op, 1))\n",
    "\n",
    "        decoder_output_logit_op = decoder_output_proj_layer(decoder_state_op)\n",
    "        output_logits.append(decoder_output_logit_op)\n",
    "\n",
    "        # if training, use input feeding i.e. teacher forcing\n",
    "        decoder_input_op = tf.cond(is_training_ph,\n",
    "                                   lambda: target_ph[:, i],\n",
    "                                   lambda: tf.argmax(decoder_output_logit_op, axis=1))\n",
    "\n",
    "    output_logits_op = tf.stack(output_logits, axis=1)\n",
    "    return output_logits_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'stack:0' shape=(?, 11, 13) dtype=float32>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "toy_batch_size = 3\n",
    "toy_vocab_size = 13\n",
    "toy_hidden_dim = 7\n",
    "toy_emb_size = 5\n",
    "toy_maxlen = 11\n",
    "\n",
    "toy_emb = tf.keras.layers.Embedding(toy_vocab_size, toy_emb_size)\n",
    "toy_dropout = tf.keras.layers.Dropout(rate=0.5)\n",
    "\n",
    "toy_input = tf.placeholder(tf.int64, [None, toy_maxlen])\n",
    "toy_target = tf.placeholder(tf.int64, [None, toy_maxlen])\n",
    "toy_mask = tf.placeholder(tf.bool, [None, toy_maxlen])\n",
    "\n",
    "is_training_ph = tf.placeholder_with_default(tf.constant(True), shape=())\n",
    "\n",
    "encoder_outputs_op, encoder_state_op = build_encoder(\n",
    "    toy_input, toy_emb, toy_dropout, toy_hidden_dim, is_training_ph)\n",
    "\n",
    "toy_logits_op = build_decoder_with_attention(\n",
    "    encoder_outputs_op, encoder_state_op, toy_target, toy_emb, toy_dropout, is_training_ph, toy_mask\n",
    ")\n",
    "\n",
    "if (toy_logits_op.shape[1:] == (toy_maxlen, toy_vocab_size)):\n",
    "    print('Test passed')\n",
    "else:\n",
    "    print('Problem with the shape')\n",
    "    print(f'Shape should be {(toy_batch_size, toy_maxlen, toy_vocab_size)}')\n",
    "    print(f'But got {toy_logits_op.shape} instead')\n",
    "\n",
    "toy_logits_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_logits_op = build_seq2seq_graph(\n",
    "    toy_input, toy_target, build_encoder, build_decoder_with_attention, toy_hidden_dim, toy_vocab_size, toy_emb_size, 0.5, is_training_ph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make model class and train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://bastings.github.io/annotated_encoder_decoder/images/bahdanau.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeppavlov.core.models.tf_model import TFModel\n",
    "# http://docs.deeppavlov.ai/en/master/_modules/deeppavlov/core/models/tf_model.html\n",
    "\n",
    "\n",
    "@register('seq2seq_57389')\n",
    "class Seq2Seq(TFModel):\n",
    "    def __init__(self, **kwargs):\n",
    "        # model hyperparameters\n",
    "        self.emb_size = kwargs['emb_size']\n",
    "        self.hidden = kwargs['hidden']\n",
    "        self.dropout = kwargs['dropout']\n",
    "        self.vocab_size = kwargs['vocab_size']\n",
    "        self.max_len = kwargs['max_len']\n",
    "\n",
    "        # optimization hyperparameters\n",
    "        self.grad_clip = kwargs.get('grad_clip', 5.)\n",
    "        self.learning_rate = kwargs.get('learning_rate', 1e-3)\n",
    "\n",
    "        # placeholders\n",
    "        self.input_ph = tf.placeholder(tf.int64, [None, self.max_len])\n",
    "        self.target_ph = tf.placeholder(tf.int64, [None, self.max_len])\n",
    "        self.is_training_ph = tf.placeholder_with_default(tf.constant(False), shape=())\n",
    "        self.target_mask_ph = tf.cast(self.target_ph > 0, tf.float32)\n",
    "\n",
    "        # graph\n",
    "        self.logits_op = build_seq2seq_graph(\n",
    "            self.input_ph,\n",
    "            self.target_ph,\n",
    "            build_encoder,\n",
    "            build_decoder_with_attention,\n",
    "            self.hidden,\n",
    "            self.vocab_size,\n",
    "            self.emb_size,\n",
    "            self.dropout,\n",
    "            self.is_training_ph)\n",
    "        self.predictions_op = tf.argmax(self.logits_op, axis=2)\n",
    "\n",
    "        self.loss = self._build_loss(self.input_ph, self.logits_op, self.target_mask_ph)\n",
    "\n",
    "        self.train_op = self.get_train_op(self.loss, self.learning_rate,\n",
    "                                          optimizer=tf.train.AdamOptimizer,\n",
    "                                          clip_norm=self.grad_clip)\n",
    "\n",
    "        # create session and initialize graph variables\n",
    "        sess_config = tf.ConfigProto()\n",
    "        sess_config.gpu_options.allow_growth = True  # do not use all GPU memory at once\n",
    "        self.sess = tf.Session(config=sess_config)\n",
    "\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        super().__init__(**kwargs)\n",
    "        if self.save_path:\n",
    "            pass\n",
    "        if self.load_path is not None:\n",
    "            self.load()\n",
    "\n",
    "    def _build_loss(self, y_true, y_logits_pred, y_mask):\n",
    "        loss = tf.keras.losses.sparse_categorical_crossentropy(y_true, y_logits_pred) * y_mask\n",
    "        loss = tf.reduce_sum(loss) / tf.reduce_sum(y_mask)\n",
    "        return loss\n",
    "\n",
    "    def _build_feed_dict(self, x, y=None):\n",
    "        feed_dict = {\n",
    "            self.input_ph: x,\n",
    "        }\n",
    "        if y is not None:\n",
    "            feed_dict.update({\n",
    "                self.target_ph: y,\n",
    "                self.is_training_ph: True,\n",
    "            })\n",
    "        return feed_dict\n",
    "\n",
    "    def train_on_batch(self, x, y):\n",
    "        feed_dict = self._build_feed_dict(x, y)\n",
    "        loss, _ = self.sess.run([self.loss, self.train_op], feed_dict=feed_dict)\n",
    "        return loss\n",
    "\n",
    "    def __call__(self, x):\n",
    "        feed_dict = self._build_feed_dict(x)\n",
    "        y_pred = self.sess.run(self.predictions_op, feed_dict=feed_dict)\n",
    "        return y_pred\n",
    "\n",
    "    def process_event(self, *args, **kwargs):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-26 06:51:45.90 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 50: No load path is set for Seq2Seq!\n"
     ]
    }
   ],
   "source": [
    "model = Seq2Seq(emb_size=3, hidden=5, dropout=0.1, vocab_size=7, max_len=9, save_path=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Postprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In postprocessing step we are going to remove all <PAD\\>, <SOS\\>, <EOS\\> tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "@register('postprocessing')\n",
    "class SentencePostprocessor(Component):\n",
    "    def __init__(self, pad_token='<PAD>', start_token='<SOS>', end_token='<EOS>', *args, **kwargs):\n",
    "        self.pad_token = pad_token\n",
    "        self.start_token = start_token\n",
    "        self.end_token = end_token\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        for i in range(len(batch)):\n",
    "            batch[i] = ' '.join(self._postproc(batch[i]))\n",
    "        return batch\n",
    "    \n",
    "    def _postproc(self, utt):\n",
    "        if self.end_token in utt:\n",
    "            utt = utt[:utt.index(self.end_token)]\n",
    "        return utt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "postprocess = SentencePostprocessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 70, 13, 240, 3, 3, 2, 0, 0], [1, 3, 2, 0, 0, 0, 0, 0, 0]]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padder(vocab([['hello', 'my', 'friend', 'there_is_no_such_word_in_dataset', 'and_this'], ['It']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<UNK> <SOS> <SOS> you you you you you you']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padder = SentencePadder(length_limit=9 - 2)\n",
    "model = Seq2Seq(emb_size=3, hidden=5, dropout=0.1, vocab_size=7, max_len=9, save_path=None)\n",
    "postprocess(vocab(model(padder(vocab([['hello', 'my', 'friend', 'there_is_no_such_word_in_dataset', 'and_this']])))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create config file\n",
    "Let's put is all together in one config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "  \"dataset_reader\": {\n",
    "    \"class_name\": \"personachat_dataset_reader\",\n",
    "    \"data_path\": \"./personachat\"\n",
    "  },\n",
    "  \"dataset_iterator\": {\n",
    "    \"class_name\": \"personachat_iterator\",\n",
    "    \"shuffle\": True\n",
    "  },\n",
    "  \"chainer\": {\n",
    "    \"in\": [\"x\"],\n",
    "    \"in_y\": [\"y\"],\n",
    "    \"pipe\": [\n",
    "      {\n",
    "        \"class_name\": \"lazy_tokenizer\",\n",
    "        \"id\": \"tokenizer\",\n",
    "        \"in\": [\"x\"],\n",
    "        \"out\": [\"x_tokens\"]\n",
    "      },\n",
    "      {\n",
    "        \"class_name\": \"lazy_tokenizer\",\n",
    "        \"id\": \"tokenizer\",\n",
    "        \"in\": [\"y\"],\n",
    "        \"out\": [\"y_tokens\"]\n",
    "      },\n",
    "      {\n",
    "        \"class_name\": \"dialog_vocab\",\n",
    "        \"id\": \"vocab\",\n",
    "        \"save_path\": \"./vocab.dict\",\n",
    "        \"load_path\": \"./vocab.dict\",\n",
    "        \"min_freq\": 2,\n",
    "        \"special_tokens\": [\"<PAD>\",\"<SOS>\", \"<EOS>\", \"<UNK>\"],\n",
    "        \"unk_token\": \"<UNK>\",\n",
    "        \"fit_on\": [\"x_tokens\", \"y_tokens\"],\n",
    "        \"in\": [\"x_tokens\"],\n",
    "        \"out\": [\"x_tokens_ids\"]\n",
    "      },\n",
    "      {\n",
    "        \"ref\": \"vocab\",\n",
    "        \"in\": [\"y_tokens\"],\n",
    "        \"out\": [\"y_tokens_ids\"]\n",
    "      },\n",
    "      {\n",
    "        \"class_name\": \"sentence_padder\",\n",
    "        \"id\": \"padder\",\n",
    "        \"length_limit\": MAXLEN,\n",
    "        \"in\": [\"x_tokens_ids\"],\n",
    "        \"out\": [\"x_tokens_ids\"]\n",
    "      },\n",
    "      {\n",
    "        \"ref\": \"padder\",\n",
    "        \"in\": [\"y_tokens_ids\"],\n",
    "        \"out\": [\"y_tokens_ids\"]\n",
    "      },\n",
    "      {\n",
    "        \"class_name\": \"seq2seq_57389\",\n",
    "        \"id\": \"seq2seq_model\",\n",
    "        \"max_len\": \"#padder.length_limit+2\",\n",
    "        \"hidden\": 250,\n",
    "        \"emb_size\": 100,\n",
    "        \"vocab_size\": len(vocab),\n",
    "        \"dropout\": 0.1,\n",
    "        \"learning_rate\": 1e-3,\n",
    "        \"save_path\": \"./seq2seq_model_57389\",\n",
    "        \"load_path\": \"./seq2seq_model_57389\",\n",
    "        \"in\": [\"x_tokens_ids\"],\n",
    "        \"in_y\": [\"y_tokens_ids\"],\n",
    "        \"out\": [\"y_predicted_tokens_ids\"],\n",
    "      },\n",
    "      {\n",
    "        \"ref\": \"vocab\",\n",
    "        \"in\": [\"y_predicted_tokens_ids\"],\n",
    "        \"out\": [\"y_predicted_tokens\"]\n",
    "      },\n",
    "      {\n",
    "        \"class_name\": \"postprocessing\",\n",
    "        \"in\": [\"y_predicted_tokens\"],\n",
    "        \"out\": [\"y_predicted_tokens\"]\n",
    "      }\n",
    "    ],\n",
    "    \"out\": [\"y_predicted_tokens\"]\n",
    "  },\n",
    "  \"train\": {\n",
    "    \"log_every_n_batches\": 500,\n",
    "    \"val_every_n_epochs\": 0,\n",
    "    \"batch_size\": 64,\n",
    "    \"validation_patience\": 5,\n",
    "    \"epochs\": 20,\n",
    "    \"metrics\": [\"bleu\"],\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interact with model using config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-26 07:15:04.624 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 103: [loading vocabulary from /home/not_a_robot/Documents/random_notebooks/CISS/vocab.dict]\n",
      "2019-06-26 07:15:17.608 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 52: [loading model from /home/not_a_robot/Documents/random_notebooks/CISS/seq2seq_model]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/not_a_robot/Documents/random_notebooks/CISS/seq2seq_model\n"
     ]
    }
   ],
   "source": [
    "model = build_model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nd nd nd nd texture texture texture texture wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana',\n",
       " 'nd nd nd nd texture wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana wana']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(['hi, how are you?', 'any ideas my dear friend?'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run experiments with and without attention, with teacher forcing and without."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('seq2seq.json', 'w') as f:\n",
    "    json.dump(config, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-26 07:15:55.221 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 103: [loading vocabulary from /home/not_a_robot/Documents/random_notebooks/CISS/vocab.dict]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-26 07:16:08.928 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 89: [saving vocabulary to /home/not_a_robot/Documents/random_notebooks/CISS/vocab.dict]\n",
      "2019-06-26 07:16:40.379 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 164: New best bleu of 0.0666\n",
      "2019-06-26 07:16:40.379 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 166: Saving model\n",
      "2019-06-26 07:16:40.380 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 76: [saving model to /home/not_a_robot/Documents/random_notebooks/CISS/seq2seq_model_57389]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 7801, \"metrics\": {\"bleu\": 0.0666}, \"time_spent\": \"0:00:20\", \"epochs_done\": 0, \"batches_seen\": 0, \"train_examples_seen\": 0, \"impatience\": 0, \"patience_limit\": 5}}\n",
      "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"bleu\": 0}, \"time_spent\": \"0:05:00\", \"epochs_done\": 0, \"batches_seen\": 500, \"train_examples_seen\": 32000, \"loss\": 9.187372651100159}}\n"
     ]
    }
   ],
   "source": [
    "from deeppavlov.core.commands.train import train_evaluate_model_from_config\n",
    "\n",
    "train_evaluate_model_from_config('seq2seq.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(config)\n",
    "model(['hi, how are you?', 'any ideas my dear friend?', 'okay, i agree with you', 'good bye!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(['tell me about yourself'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra\n",
    "### Decoder with attention math 2 (more realistic case)\n",
    "\n",
    "This is typical NMT decoder with attention. It uses a lot of hacky tricks to make decoding a bit better.\n",
    "\n",
    "Decoder is much more tricky then encoder, especially with attention.\n",
    "So it would be better for us to write down all decoder operations mathematically.\n",
    "\n",
    "Let $m$ be the length of a source sequence, $h$ be dimension of encoder output, $\\operatorname E \\in \\mathbb{R}^{ vocab\\_size \\times emb\\_size}$ - embedding matrix.\n",
    "\n",
    "Before encoding we have:\n",
    "$$\n",
    "\\mathbf{h}_i^{enc} \\in \\mathbb{R}^h - \\text{encoder output at i-th timestamp}\\\\\n",
    "\\mathbf{h}_m^{enc} - \\text{last encoder output (encoder state)}\\\\\n",
    "$$\n",
    "\n",
    "#### Zeroth step\n",
    "\n",
    "At the zeroth decoding step we sould construct decoder **input** and decoder **initial state**.\n",
    "Decoder **initial state** is transformed (projected with matrix $\\mathbf{\\operatorname{W}}_h$) encoder state.\n",
    "Decoder **input** is _zero_ vector of size $h$.\n",
    "\n",
    "Let $sos$ be SOS-token index in embedding matrix.\n",
    "\n",
    "$$\n",
    "\\mathbf{h}_o^{dec} = \\operatorname{W}_h \\mathbf{h}_m, \\; \\operatorname{W}_h \\in \\mathbb{R}^{h \\times 2h} - \\text{decoder initial state is transformed encoder state}\\\\\n",
    "\\mathbf{e}_0 = \\operatorname{E}[sos]\\\\\n",
    "\\mathbf{o}_0 = \\mathbf 0, \\mathbf{o}_0 \\in \\mathbb{R}^h\\\\\n",
    "\\mathbf{h}_1^{dec} = \\operatorname{Decoder}([e_0; o_0])\n",
    "$$\n",
    "\n",
    "#### t-th step, t > 0\n",
    "\n",
    "At t-th step decoder **input** is concatenated combined-output vector $\\mathbf{o}_t$ (it is explained down this page in Attention paragraph) and previous predicted token embedding.\n",
    "\n",
    "**Note:** at training time we use **teacher forcing** (it is also called input feeding) that means that instead of using previous predicted token decoder uses previous true token from target sequence.\n",
    "\n",
    "\n",
    "#### Attention\n",
    "\n",
    "When we got decoder state $h_1$, we can compute attention vector.\n",
    "\n",
    "Let $\\operatorname{W}_{attProj} \\in \\mathbb{R}^{h \\times 2h}$ be attention weighs, $\\mathbf{s}$ be attention scores.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbf{s}_{t, i} &= (h_t^{dec})^T \\operatorname{W}_{attProj} h_i^{enc}\\\\\n",
    "\\mathbf{\\alpha}_t &= \\operatorname{Softmax}(\\mathbf{s}_t) \\text{  }\\\\\n",
    "\\mathbf{a}_t &= \\sum_i^m \\alpha_{t, i} \\mathbf{h}_i^{enc}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Then, decoder output is concatenated with attention vector and passed through a linear layer, tanh and dropout to attain combined-output vector $\\mathbf{o}_t$.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbf{u}_t = [a_t; h_t^{dec}]\n",
    "    \\text{   } \\; &where \\; \\text{  }\n",
    "        \\mathbf{u}_t \\in \\mathbb{R}^{3h \\times 1}\\\\\n",
    "\\mathbf{o}_t = \\operatorname{Dropout(tanh(W_u} \\mathbf{u}_t))\n",
    "    \\text{   } \\;  &where  \\text{   } \\; \n",
    "        \\operatorname{W}_u \\in \\mathbb{R}^{h \\times 3h}, \\mathbf{o}_t \\in \\mathbb{R}^{h \\times 1}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
