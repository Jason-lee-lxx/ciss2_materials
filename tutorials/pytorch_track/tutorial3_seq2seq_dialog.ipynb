{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import shutil\n",
    "import zipfile\n",
    "import gzip\n",
    "import pickle\n",
    "import itertools\n",
    "import urllib.parse\n",
    "import urllib.request\n",
    "from collections import Counter\n",
    "import functools\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from nltk import word_tokenize\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this turorial, we will train a simple recurrent sequence-to-sequnce dialog model using the [OpenSubtitles](http://opus.nlpl.eu/OpenSubtitles.php) dataset. This dataset contains already tokenized subtitles collected from http://www.opensubtitles.org/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the previous tutorial, we are going to use a `Voacbulary` class, and a subclass of the `torch.utils.data.Dataset` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maybe_download_and_unzip_file(file_url, file_name=None):\n",
    "    if file_name is None:\n",
    "        file_name = os.path.basename(file_url)\n",
    "        \n",
    "    if not os.path.exists(file_name):\n",
    "        print(f'Downloading: {file_name}')\n",
    "        \n",
    "        with urllib.request.urlopen(file_url) as response, open(file_name, 'wb') as target_file:\n",
    "            shutil.copyfileobj(response, target_file)\n",
    "\n",
    "        print(f'Downloaded: {file_name}')\n",
    "\n",
    "        file_extension = os.path.splitext(file_name)[1]\n",
    "        if file_extension == '.zip':\n",
    "            print(f'Extracting zip: {file_name}')\n",
    "            with zipfile.ZipFile(file_name, 'r') as zip_file:\n",
    "                zip_file.extractall('.')\n",
    "                \n",
    "    else:\n",
    "        print(f'Exists: {file_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_url = 'http://opus.nlpl.eu/download.php?f=OpenSubtitles/v2018/mono/OpenSubtitles.en.gz'\n",
    "dataset_filename = 'OpenSubtitles.en.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exists: OpenSubtitles.en.gz\n"
     ]
    }
   ],
   "source": [
    "maybe_download_and_unzip_file(dataset_url, dataset_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab(object):\n",
    "    END_TOKEN = '<end>'\n",
    "    START_TOKEN = '<start>'\n",
    "    PAD_TOKEN = '<pad>'\n",
    "    UNK_TOKEN = '<unk>'\n",
    "\n",
    "    def __init__(self, special_tokens=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.special_tokens = special_tokens\n",
    "\n",
    "        self.token2id = {}\n",
    "        self.id2token = {}\n",
    "\n",
    "        self.token_counts = Counter()\n",
    "\n",
    "        if self.special_tokens is not None:\n",
    "            self.add_document(self.special_tokens)\n",
    "\n",
    "    def add_document(self, document, rebuild=True):\n",
    "        for token in document:\n",
    "            self.token_counts[token] += 1\n",
    "\n",
    "            if token not in self.token2id:\n",
    "                self.token2id[token] = len(self.token2id)\n",
    "\n",
    "        if rebuild:\n",
    "            self._rebuild_id2token()\n",
    "\n",
    "    def add_documents(self, documents):\n",
    "        for doc in documents:\n",
    "            self.add_document(doc, rebuild=False)\n",
    "\n",
    "        self._rebuild_id2token()\n",
    "\n",
    "    def prune_vocab(self, max_size):\n",
    "        nb_tokens_before = len(self.token2id)\n",
    "\n",
    "        tokens_all = set(self.token2id.keys())\n",
    "        tokens_special = set(self.special_tokens)\n",
    "        tokens_most_common = set(t for t, c in self.token_counts.most_common(max_size)) - tokens_special\n",
    "        tokens_to_delete = tokens_all - tokens_most_common - tokens_special\n",
    "\n",
    "        for token in tokens_to_delete:\n",
    "            self.token_counts.pop(token)\n",
    "\n",
    "        self.token2id = {}\n",
    "        for i, token in enumerate(self.special_tokens):\n",
    "            self.token2id[token] = i\n",
    "        for i, token in enumerate(tokens_most_common):\n",
    "            self.token2id[token] = i + len(self.special_tokens)\n",
    "\n",
    "        self._rebuild_id2token()\n",
    "\n",
    "        nb_tokens_after = len(self.token2id)\n",
    "\n",
    "        print(f'Vocab pruned: {nb_tokens_before} -> {nb_tokens_after}')\n",
    "\n",
    "    def _rebuild_id2token(self):\n",
    "        self.id2token = {i: t for t, i in self.token2id.items()}\n",
    "\n",
    "    def get(self, item, default=None):\n",
    "        return self.token2id.get(item, default)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.token2id[item]\n",
    "\n",
    "    def __contains__(self, item):\n",
    "        return item in self.token2id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.token2id)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'{len(self)} tokens'\n",
    "\n",
    "    def save(self, filename):\n",
    "        with open(filename, 'w') as csv_file:\n",
    "            writer = csv.DictWriter(csv_file, fieldnames=['token', 'counts', 'is_special'])\n",
    "            writer.writeheader()\n",
    "            for idx in range(len(self.token2id)):\n",
    "                token = self.id2token[idx]\n",
    "                is_special = 1 if token in self.special_tokens else 0\n",
    "                writer.writerow({'token': token, 'counts': self.token_counts[token], 'is_special': is_special})\n",
    "        \n",
    "    @staticmethod\n",
    "    def load(filename):\n",
    "        with open(filename, 'r') as csv_file:\n",
    "            token2id = {}\n",
    "            tokens_counts = {}\n",
    "            special_tokens = []\n",
    "            reader = csv.DictReader(csv_file)\n",
    "            for i, row in enumerate(reader):\n",
    "                token2id[row['token']] = i\n",
    "                tokens_counts[row['token']] = int(row['counts'])\n",
    "                if bool(int(row['is_special'])):\n",
    "                    special_tokens.append(row['token'])\n",
    "                \n",
    "                \n",
    "        vocab = Vocab()\n",
    "        vocab.token2id = token2id\n",
    "        vocab.token_counts = Counter(tokens_counts)\n",
    "        vocab.special_tokens = special_tokens\n",
    "        vocab._rebuild_id2token()\n",
    "        \n",
    "        return vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two important differences with the previous tutorial. First, notice how we form `<query>,<response>` pairs from a sequence of subtitles. Next, since the vocabulary can be quite large, we prune it to contain only the top 50,000 most common tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubtitlesDialogDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, filename, vocab=None, max_lines = 1000, max_len=50, max_vocab_size=50000):\n",
    "\n",
    "        self.lines = []\n",
    "        with gzip.open(filename, 'rb') as f:\n",
    "            for i, line in enumerate(f):\n",
    "                if i >= max_lines:\n",
    "                    break\n",
    "\n",
    "                tokens = word_tokenize(line.decode('utf-8'))\n",
    "                self.lines.append(tokens)\n",
    "\n",
    "        self.max_lines = min(len(self.lines), max_lines)\n",
    "                \n",
    "        if vocab is None:\n",
    "            vocab = Vocab(special_tokens=[Vocab.PAD_TOKEN, Vocab.START_TOKEN, Vocab.END_TOKEN, Vocab.UNK_TOKEN])\n",
    "            vocab.add_documents(self.lines)\n",
    "            vocab.prune_vocab(max_vocab_size)\n",
    "\n",
    "            print(f'Created vocab: {vocab}')\n",
    "\n",
    "            \n",
    "        if max_len is None:\n",
    "            max_len = max(len(s) for s in itertools.chain.from_iterable(self.sentences))\n",
    "            print(f'Calculed max len: {max_len}')\n",
    "        \n",
    "        self.vocab = vocab\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def _pad_sentnece(self, sent):\n",
    "        sent = sent[:self.max_len - 1] + [Vocab.END_TOKEN,]\n",
    "        \n",
    "        nb_pad = self.max_len - len(sent)\n",
    "        sent = sent + [Vocab.PAD_TOKEN,] * nb_pad\n",
    "        \n",
    "        return sent\n",
    "        \n",
    "    def _process_sent(self, sent):\n",
    "        sent = self._pad_sentnece(sent)\n",
    "        sent = [self.vocab[t] if t in self.vocab else self.vocab[Vocab.UNK_TOKEN] for t in sent]\n",
    "        \n",
    "        sent = np.array(sent, dtype=np.long)\n",
    "        return sent\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        query = self.lines[index]\n",
    "        response = self.lines[index+1]\n",
    "        \n",
    "        query = self._process_sent(query)\n",
    "        response = self._process_sent(response)        \n",
    "        \n",
    "        return query, response\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.max_lines - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab pruned: 57727 -> 50000\n",
      "Created vocab: 50000 tokens\n"
     ]
    }
   ],
   "source": [
    "dataset = SubtitlesDialogDataset(dataset_filename, max_lines=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999999"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_filename = 'tmp/seq2seq_dialog.vocab.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.vocab.save(vocab_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the same word embeddings, as in the previous tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_url = 'https://mednli.blob.core.windows.net/shared/word_embeddings/crawl-300d-2M.pickled'\n",
    "embeddings_filename = 'crawl-300d-2M.pickled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exists: crawl-300d-2M.pickled\n"
     ]
    }
   ],
   "source": [
    "maybe_download_and_unzip_file(embeddings_url, embeddings_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(embeddings_filename, 'rb') as pkl_file:\n",
    "    word_embeddings = pickle.load(pkl_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings_matrix(word_embeddings, vocab):\n",
    "    embedding_size = word_embeddings[list(word_embeddings.keys())[0]].shape[0]\n",
    "\n",
    "    W_emb = np.zeros((len(vocab), embedding_size), dtype=np.float32)\n",
    "    \n",
    "    special_tokens = {\n",
    "        t: np.random.uniform(-0.3, 0.3, (embedding_size,))\n",
    "        for t in (Vocab.UNK_TOKEN, )\n",
    "    }\n",
    "    special_tokens[Vocab.PAD_TOKEN] = np.zeros((embedding_size,))\n",
    "\n",
    "    nb_unk = 0\n",
    "    for i, t in vocab.id2token.items():\n",
    "        if t in special_tokens:\n",
    "            W_emb[i] = special_tokens[t]\n",
    "        else:\n",
    "            if t in word_embeddings:\n",
    "                W_emb[i] = word_embeddings[t]\n",
    "            else:\n",
    "                W_emb[i] = np.random.uniform(-0.3, 0.3, embedding_size)\n",
    "                nb_unk += 1\n",
    "\n",
    "    print(f'Nb unk: {nb_unk}')\n",
    "\n",
    "    return W_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb unk: 5182\n"
     ]
    }
   ],
   "source": [
    "W_emb = create_embeddings_matrix(word_embeddings, dataset.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use a standard seq2seq model. Given an input query (sentence), the model produces a response. Although this model does not have any context information, it provides a good starting point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqModel(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size, teacher_forcing,\n",
    "                 max_len,trainable_embeddings, start_index, end_index, pad_index, W_emb=None):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.teacher_forcing = teacher_forcing\n",
    "        self.max_len = max_len\n",
    "        self.start_index = start_index\n",
    "        self.end_index = end_index\n",
    "        self.pad_index = pad_index\n",
    "        \n",
    "        self.embedding = torch.nn.Embedding(vocab_size, embedding_size, padding_idx=pad_index)\n",
    "        if W_emb is not None:\n",
    "            self.embedding.weight.data.copy_(torch.from_numpy(W_emb))\n",
    "        if not trainable_embeddings:\n",
    "            self.embedding.weight.requires_grad = False\n",
    "\n",
    "        self.encoder = torch.nn.GRU(embedding_size, hidden_size, batch_first=True)\n",
    "        self.decoder = torch.nn.GRUCell(embedding_size, hidden_size)\n",
    "        self.decoder_projection = torch.nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "            \n",
    "    def encode(self, inputs):\n",
    "        batch_size = inputs.size(0)\n",
    "        inputs_lengths = torch.sum(inputs != self.pad_index, dim=1).long()\n",
    "        \n",
    "        inputs_emb = self.embedding(inputs)\n",
    "        outputs, h = self.encoder(inputs_emb)\n",
    "        \n",
    "        h_last_hidden = outputs[np.arange(batch_size), inputs_lengths - 1]\n",
    "        \n",
    "        return h_last_hidden\n",
    "    \n",
    "    def decode(self, decoder_hidden, targets=None):\n",
    "        batch_size = decoder_hidden.size(0)\n",
    "        \n",
    "        outputs_logits = []\n",
    "        decoder_inputs = torch.full_like(decoder_hidden[:, 0], self.start_index).long()\n",
    "        for i in range(self.max_len):\n",
    "            decoder_inputs_emb = self.embedding(decoder_inputs)\n",
    "            \n",
    "            decoder_hidden = self.decoder(decoder_inputs_emb, decoder_hidden)\n",
    "            \n",
    "            decoder_output_logit = self.decoder_projection(decoder_hidden)\n",
    "            \n",
    "            if np.random.rand() < self.teacher_forcing and targets is not None:\n",
    "                decoder_inputs = targets[:, i]\n",
    "            else:\n",
    "                decoder_inputs = decoder_output_logit.argmax(dim=1).long()\n",
    "            \n",
    "            outputs_logits.append(decoder_output_logit)\n",
    "            \n",
    "        outputs_logits = torch.stack(outputs_logits, dim=1)\n",
    "            \n",
    "        return outputs_logits\n",
    "        \n",
    "    def forward(self, inputs, targets=None):\n",
    "        decoder_hidden = self.encode(inputs)\n",
    "        outputs_logits = self.decode(decoder_hidden, targets)\n",
    "\n",
    "        return outputs_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_masked(inputs, mask, dim=1, epsilon=0.000001):\n",
    "    inputs_exp = torch.exp(inputs)\n",
    "    inputs_exp = inputs_exp * mask.float()\n",
    "    inputs_exp_sum = inputs_exp.sum(dim=dim)\n",
    "    inputs_attention = inputs_exp / (inputs_exp_sum.unsqueeze(dim) + epsilon)\n",
    "\n",
    "    return inputs_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqAttentionModel(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size, teacher_forcing,\n",
    "                 max_len,trainable_embeddings, start_index, end_index, pad_index, W_emb=None):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.teacher_forcing = teacher_forcing\n",
    "        self.max_len = max_len\n",
    "        self.start_index = start_index\n",
    "        self.end_index = end_index\n",
    "        self.pad_index = pad_index\n",
    "        \n",
    "        self.embedding = torch.nn.Embedding(vocab_size, embedding_size, padding_idx=pad_index)\n",
    "        if W_emb is not None:\n",
    "            self.embedding.weight.data.copy_(torch.from_numpy(W_emb))\n",
    "        if not trainable_embeddings:\n",
    "            self.embedding.weight.requires_grad = False\n",
    "\n",
    "        self.encoder = torch.nn.GRU(embedding_size, hidden_size, batch_first=True)\n",
    "        self.decoder = torch.nn.GRUCell(embedding_size, hidden_size)\n",
    "\n",
    "        self.attention_decoder = torch.nn.Linear(hidden_size, hidden_size)\n",
    "        self.attention_encoder = torch.nn.Linear(hidden_size, hidden_size)        \n",
    "        self.attention_reduce = torch.nn.Linear(hidden_size, 1, bias=False)                \n",
    "        self.decoder_hidden_combine = torch.nn.Linear(hidden_size * 2, hidden_size)\n",
    "        \n",
    "        self.decoder_projection = torch.nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "            \n",
    "    def encode(self, inputs):\n",
    "        batch_size = inputs.size(0)\n",
    "        inputs_mask = (inputs != self.pad_index).long()\n",
    "        inputs_lengths = torch.sum(inputs_mask, dim=1)\n",
    "        \n",
    "        inputs_emb = self.embedding(inputs)\n",
    "        outputs, h = self.encoder(inputs_emb)\n",
    "        \n",
    "#         h_last_hidden = outputs[np.arange(batch_size), inputs_lengths - 1]\n",
    "        \n",
    "        return outputs, inputs_mask\n",
    "    \n",
    "    def decode(self, encoder_hiddens, inputs_mask, targets=None):\n",
    "        batch_size = encoder_hiddens.size(0)\n",
    "\n",
    "        outputs_logits = []\n",
    "        decoder_hidden = torch.zeros_like(encoder_hiddens[:,0,:])\n",
    "        decoder_inputs = torch.full_like(decoder_hidden[:, 0], self.start_index).long()\n",
    "        for i in range(self.max_len):\n",
    "            decoder_inputs_emb = self.embedding(decoder_inputs)\n",
    "            \n",
    "            att_enc = self.attention_encoder(encoder_hiddens)\n",
    "            att_dec = self.attention_decoder(decoder_hidden)\n",
    "            att = torch.tanh(att_enc + att_dec.unsqueeze(1))\n",
    "            att_reduced = self.attention_reduce(att).squeeze(-1)\n",
    "            att_normazlied = softmax_masked(att_reduced, inputs_mask)\n",
    "\n",
    "            decoder_hidden_att = torch.sum(encoder_hiddens * att_normazlied.unsqueeze(-1), dim=1)\n",
    "            decoder_hidden_combined = self.decoder_hidden_combine(torch.cat([decoder_hidden, decoder_hidden_att], dim=-1))\n",
    "            \n",
    "            decoder_hidden = self.decoder(decoder_inputs_emb, decoder_hidden_combined)\n",
    "            \n",
    "            decoder_output_logit = self.decoder_projection(decoder_hidden)\n",
    "            \n",
    "            if np.random.rand() < self.teacher_forcing and targets is not None:\n",
    "                decoder_inputs = targets[:, i]\n",
    "            else:\n",
    "                decoder_inputs = decoder_output_logit.argmax(dim=1).long()\n",
    "            \n",
    "            outputs_logits.append(decoder_output_logit)\n",
    "            \n",
    "        outputs_logits = torch.stack(outputs_logits, dim=1)\n",
    "            \n",
    "        return outputs_logits\n",
    "        \n",
    "    def forward(self, inputs, targets=None):\n",
    "        encoder_hiddens, inputs_mask = self.encode(inputs)\n",
    "        outputs_logits = self.decode(encoder_hiddens, inputs_mask, targets)\n",
    "\n",
    "        return outputs_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are some helper functions to save and load the weights of the model. Feel free to use them in your projects!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_class, filename):\n",
    "    def _map_location(storage, loc):\n",
    "        return storage\n",
    "\n",
    "    # load trained on GPU models to CPU\n",
    "    map_location = None\n",
    "    if not torch.cuda.is_available():\n",
    "        map_location = _map_location\n",
    "\n",
    "    state = torch.load(str(filename), map_location=map_location)\n",
    "\n",
    "    model = model_class(**state['model_params'])\n",
    "    model.load_state_dict(state['model_state'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def save_model(model, filename, model_params=None):\n",
    "    if isinstance(model, torch.nn.DataParallel):\n",
    "        model = model.module\n",
    "\n",
    "    state = {\n",
    "        'model_params': model_params or {},\n",
    "        'model_state': model.state_dict(),\n",
    "    }\n",
    "\n",
    "    torch.save(state, str(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "trainable_embeddings = True\n",
    "teacher_forcing = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = dict(\n",
    "    hidden_size=hidden_size,\n",
    "    trainable_embeddings=trainable_embeddings,\n",
    "    teacher_forcing=teacher_forcing,\n",
    "\n",
    "    vocab_size = len(dataset.vocab),\n",
    "    embedding_size=W_emb.shape[1],\n",
    "    max_len=dataset.max_len,\n",
    "    start_index=dataset.vocab[Vocab.START_TOKEN],\n",
    "    end_index=dataset.vocab[Vocab.END_TOKEN], \n",
    "    pad_index=dataset.vocab[Vocab.PAD_TOKEN],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2SeqAttentionModel(**model_params, W_emb=W_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2SeqAttentionModel(\n",
       "  (embedding): Embedding(50000, 300, padding_idx=0)\n",
       "  (encoder): GRU(300, 256, batch_first=True)\n",
       "  (decoder): GRUCell(300, 256)\n",
       "  (attention_decoder): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (attention_encoder): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (attention_reduce): Linear(in_features=256, out_features=1, bias=False)\n",
       "  (decoder_hidden_combine): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (decoder_projection): Linear(in_features=256, out_features=50000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = 'tmp/seq2seq_dialog_att.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=128\n",
    "nb_epochs = 500\n",
    "learning_rate=0.001\n",
    "weight_decay = 0.000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,weight_decay=weight_decay)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40950bb72e6147dda7845b740fc6cf31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epochs', max=500, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=7813, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss 0.8906596688551068\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3490101cc254a27b2cf1b6e96ef521f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=7813, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses = []\n",
    "\n",
    "for epoch in tqdm_notebook(range(nb_epochs), desc='Epochs'):\n",
    "    epoch_losses = []\n",
    "    for i, (query, response) in enumerate(tqdm_notebook(dataloader, desc='Iteration', leave=False)):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        query = query.to('cuda')\n",
    "        response = response.to('cuda')        \n",
    "        \n",
    "        response_logits = model(query, response)\n",
    "    \n",
    "        # reshape for the cross entropy loss\n",
    "        response_logits = response_logits.view(-1, response_logits.size(2))\n",
    "        response = response.view(-1)\n",
    "        loss = criterion(response_logits, response)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_losses.append(loss.item())\n",
    "\n",
    "    epoch_loss = np.mean(epoch_losses)\n",
    "        \n",
    "    losses.append(epoch_loss)\n",
    "    print('Epoch {}, loss {}'.format(epoch, epoch_loss))\n",
    "    \n",
    "    save_model(model, model_filename, model_params=model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(np.arange(len(losses)), losses)\n",
    "\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try some inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(Seq2SeqModel, model_filename)\n",
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(query, model, dataset):\n",
    "    if not isinstance(query, list):\n",
    "        query = word_tokenize(query)\n",
    "        \n",
    "    query = dataset._process_sent(query)\n",
    "    query = torch.tensor(query).to('cuda')\n",
    "        \n",
    "    response_logits = model(query.view(1, -1)).squeeze(0)\n",
    "    response_indices = response_logits.argmax(dim=-1).cpu().numpy()\n",
    "    \n",
    "    response = [dataset.vocab.id2token[int(idx)] for idx in response_indices]\n",
    "    response = [t for t in response if t not in dataset.vocab.special_tokens]\n",
    "    response = ' '.join(response)\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'How are you?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_response(query, model, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_response(text_widget):\n",
    "    query = text_widget.value\n",
    "    response = generate_response(query, model, dataset)\n",
    "    print(f'{query} -> {response}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_input = widgets.Text(value='How are you?')\n",
    "text_input.on_submit(print_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
